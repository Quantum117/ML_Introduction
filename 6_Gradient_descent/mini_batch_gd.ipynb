{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T15:45:37.621527Z",
     "start_time": "2025-06-24T15:45:37.616009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "id": "26c5b824c25a28a2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T15:45:37.674359Z",
     "start_time": "2025-06-24T15:45:37.662941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "\n",
    "class MiniBatchGradientDescend:\n",
    "    def __init__(self, lr, max_iter, tol,batch_size):\n",
    "        self.lr = lr # learning rate\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.weights_ = None\n",
    "        self.intercept_ = None\n",
    "        self.batch_size = batch_size\n",
    "        # save losses to a list\n",
    "        self.lossi = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        n = X.shape[0]\n",
    "\n",
    "        X = np.c_[np.ones(n), X]\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        # 1. Initialize weights randomly\n",
    "        weights = np.ones(n_features)/100000\n",
    "\n",
    "        converged = False\n",
    "        m = self.batch_size\n",
    "        for epoch in range(self.max_iter): # continue max_iter times\n",
    "           for j in range(n // self.batch_size):\n",
    "                X_batch = X[j*m:(j+1)*m-1]\n",
    "                y_batch = y[j*m:(j+1)*m-1]\n",
    "\n",
    "                y_pred = X_batch @ weights\n",
    "                e = y_batch - y_pred\n",
    "\n",
    "                loss = root_mean_squared_error(y_batch, y_pred)\n",
    "                self.lossi.append(loss)\n",
    "\n",
    "                coef_grad = (-2) * X_batch.T @ e\n",
    "\n",
    "                if np.linalg.norm(self.lr *coef_grad) < self.tol:\n",
    "                    converged = True\n",
    "                    break\n",
    "\n",
    "                weights = weights - self.lr * coef_grad\n",
    "\n",
    "        if not converged:\n",
    "            print(f\"Warning: Did not converge after {self.max_iter} steps.\")\n",
    "\n",
    "        # 4. Repeat this process self.max_iter times\n",
    "\n",
    "        self.weights_ = weights[1:]\n",
    "        self.intercept_ = weights[0]\n",
    "        self.step = epoch\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        return X @ self.weights_ + self.intercept_\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        mse = np.mean((y - y_pred) ** 2)\n",
    "        return 1 - mse / np.var(y)  # R^2 score\n",
    "\n",
    "\n",
    "mb = MiniBatchGradientDescend(lr=0.01, max_iter=10, tol=0.001, batch_size=10)\n"
   ],
   "id": "2ede7e5990e96cd7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T15:45:38.056165Z",
     "start_time": "2025-06-24T15:45:37.721898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "df2 = pd.read_csv('advertising.csv')\n",
    "\n",
    "X1 = df2.iloc[:, :-1]\n",
    "y1 = df2.iloc[:, -1]\n",
    "X1_scaled = pd.DataFrame(sc.fit_transform(X1), columns=X1.columns)\n",
    "\n",
    "mb.fit(X1, y1)"
   ],
   "id": "81f9167cca2b56f7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:584: RuntimeWarning: overflow encountered in square\n",
      "  output_errors = _average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13136\\3961060553.py:40: RuntimeWarning: overflow encountered in matmul\n",
      "  coef_grad = (-2) * X_batch.T @ e\n",
      "C:\\Users\\Lenovo\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2791: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 9\u001B[39m\n\u001B[32m      6\u001B[39m y1 = df2.iloc[:, -\u001B[32m1\u001B[39m]\n\u001B[32m      7\u001B[39m X1_scaled = pd.DataFrame(sc.fit_transform(X1), columns=X1.columns)\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[43mmb\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my1\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 37\u001B[39m, in \u001B[36mMiniBatchGradientDescend.fit\u001B[39m\u001B[34m(self, X, y)\u001B[39m\n\u001B[32m     34\u001B[39m y_pred = X_batch @ weights\n\u001B[32m     35\u001B[39m e = y_batch - y_pred\n\u001B[32m---> \u001B[39m\u001B[32m37\u001B[39m loss = \u001B[43mroot_mean_squared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[38;5;28mself\u001B[39m.lossi.append(loss)\n\u001B[32m     40\u001B[39m coef_grad = (-\u001B[32m2\u001B[39m) * X_batch.T @ e\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:665\u001B[39m, in \u001B[36mroot_mean_squared_error\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput)\u001B[39m\n\u001B[32m    615\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Root mean squared error regression loss.\u001B[39;00m\n\u001B[32m    616\u001B[39m \n\u001B[32m    617\u001B[39m \u001B[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    659\u001B[39m \u001B[33;03m0.822...\u001B[39;00m\n\u001B[32m    660\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    662\u001B[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001B[32m    664\u001B[39m output_errors = xp.sqrt(\n\u001B[32m--> \u001B[39m\u001B[32m665\u001B[39m     \u001B[43mmean_squared_error\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    666\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m=\u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mraw_values\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\n\u001B[32m    667\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    668\u001B[39m )\n\u001B[32m    670\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(multioutput, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    671\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m multioutput == \u001B[33m\"\u001B[39m\u001B[33mraw_values\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:191\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    189\u001B[39m global_skip_validation = get_config()[\u001B[33m\"\u001B[39m\u001B[33mskip_parameter_validation\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m    190\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[32m--> \u001B[39m\u001B[32m191\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    193\u001B[39m func_sig = signature(func)\n\u001B[32m    195\u001B[39m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:580\u001B[39m, in \u001B[36mmean_squared_error\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput)\u001B[39m\n\u001B[32m    530\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Mean squared error regression loss.\u001B[39;00m\n\u001B[32m    531\u001B[39m \n\u001B[32m    532\u001B[39m \u001B[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    576\u001B[39m \u001B[33;03m0.825...\u001B[39;00m\n\u001B[32m    577\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    578\u001B[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001B[32m    579\u001B[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001B[32m--> \u001B[39m\u001B[32m580\u001B[39m     \u001B[43m_check_reg_targets_with_floating_dtype\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    581\u001B[39m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\n\u001B[32m    582\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    583\u001B[39m )\n\u001B[32m    584\u001B[39m output_errors = _average((y_true - y_pred) ** \u001B[32m2\u001B[39m, axis=\u001B[32m0\u001B[39m, weights=sample_weight)\n\u001B[32m    586\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(multioutput, \u001B[38;5;28mstr\u001B[39m):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001B[39m, in \u001B[36m_check_reg_targets_with_floating_dtype\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001B[39m\n\u001B[32m    160\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001B[39;00m\n\u001B[32m    161\u001B[39m \n\u001B[32m    162\u001B[39m \u001B[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    205\u001B[39m \u001B[33;03m    correct keyword.\u001B[39;00m\n\u001B[32m    206\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    207\u001B[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001B[32m--> \u001B[39m\u001B[32m209\u001B[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m    \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:116\u001B[39m, in \u001B[36m_check_reg_targets\u001B[39m\u001B[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001B[39m\n\u001B[32m    114\u001B[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[32m    115\u001B[39m y_true = check_array(y_true, ensure_2d=\u001B[38;5;28;01mFalse\u001B[39;00m, dtype=dtype)\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m y_pred = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    118\u001B[39m     sample_weight = _check_sample_weight(sample_weight, y_true, dtype=dtype)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1099\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1100\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFound array with dim \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marray.ndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1101\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m while dim <= 2 is required\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcontext\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1102\u001B[39m     )\n\u001B[32m   1104\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ensure_all_finite:\n\u001B[32m-> \u001B[39m\u001B[32m1105\u001B[39m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1106\u001B[39m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1107\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mensure_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[32m   1113\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m   1114\u001B[39m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001B[39m, in \u001B[36m_assert_all_finite\u001B[39m\u001B[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[32m    118\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    121\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    122\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    123\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML_Introduction\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001B[39m, in \u001B[36m_assert_all_finite_element_wise\u001B[39m\u001B[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name == \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[32m    153\u001B[39m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[32m    154\u001B[39m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[32m    155\u001B[39m     msg_err += (\n\u001B[32m    156\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not accept missing values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    167\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#estimators-that-handle-nan-values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    168\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[31mValueError\u001B[39m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
